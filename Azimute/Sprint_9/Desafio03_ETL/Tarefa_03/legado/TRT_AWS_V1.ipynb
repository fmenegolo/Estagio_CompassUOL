{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"# AWS Glue Studio Notebook\n",
				"##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"#### Optional: Run this cell to see available notebook commands (\"magics\").\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"####  Run this cell to set up and start your interactive session.\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Welcome to the Glue Interactive Sessions Kernel\n",
						"For more information on available magic commands, please type %help in any new cell.\n",
						"\n",
						"Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
						"Installed kernel version: 0.37.3 \n",
						"Current idle_timeout is 2800 minutes.\n",
						"idle_timeout has been set to 59 minutes.\n",
						"Setting Glue version to: 3.0\n",
						"Previous worker type: G.1X\n",
						"Setting new worker type to: G.1X\n",
						"Previous number of workers: 5\n",
						"Setting new number of workers to: 2\n",
						"Authenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::214541855063:role/AWSGlueServiceRole-Lab4\n",
						"Trying to create a Glue session for the kernel.\n",
						"Worker Type: G.1X\n",
						"Number of Workers: 2\n",
						"Session ID: 5aa0e6bf-d11a-4e14-8b93-a7f61ea250bd\n",
						"Job Type: glueetl\n",
						"Applying the following default arguments:\n",
						"--glue_kernel_version 0.37.3\n",
						"--enable-glue-datacatalog true\n",
						"Waiting for session 5aa0e6bf-d11a-4e14-8b93-a7f61ea250bd to get into ready status...\n",
						"Session 5aa0e6bf-d11a-4e14-8b93-a7f61ea250bd has been created.\n",
						"\n"
					]
				}
			],
			"source": [
				"%idle_timeout 59\n",
				"%glue_version 3.0\n",
				"%worker_type G.1X\n",
				"%number_of_workers 2\n",
				"\n",
				"\n",
				"import sys\n",
				"from awsglue.transforms import *\n",
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.job import Job\n",
				"from pyspark.sql.functions import col, substring, when, size\n",
				"from datetime import datetime\n",
				"\n",
				"  \n",
				"sc = SparkContext.getOrCreate()\n",
				"glueContext = GlueContext(sc)\n",
				"spark = glueContext.spark_session\n",
				"job = Job(glueContext)\n",
				"\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Define os caminhos dos arquivos no S3\n",
				"path1 = \"s3://data-lake-do-fabricio/Raw/Local/CSV/Movies/2023/05/02/\"\n",
				"path2 = \"s3://data-lake-do-fabricio/Raw/Local/CSV/Series/2023/05/02/\"\n",
				"path3 = \"s3://data-lake-do-fabricio/Raw/TMDB/JSON/Movies/2023/05/24/\"\n",
				"path4 = \"s3://data-lake-do-fabricio/Raw/TMDB/JSON/Series/2023/05/24/\"\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Carrega os DataFrames\n",
				"df_movies_IMDB = spark.read.option(\"delimiter\", \"|\").csv(path1 + 'movies.csv', header=True)\n",
				"df_series_IMDB = spark.read.option(\"delimiter\", \"|\").csv(path2 + 'series.csv', header=True)\n",
				"df_movies_TMDB = spark.read.json(path3 + 'movies_20230524_160604.json') \n",
				"df_series_TMDB = spark.read.json(path4 + 'series_20230524_160604.json')"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 2. \n",
				" Filtro os Filmes do BD Local com lista de filmes do TMDB"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Converter a coluna 'title' do DataFrame JSON para um array de palavras e extrair o ano de lançamento\n",
				"df_filmes_titulos_datas = df_movies_TMDB.select(col('title'), substring(col('release_date'), 1, 4).alias('releaseDate'))\n",
				"\n",
				"# Realizar a filtragem dos títulos\n",
				"df_movies_IMDB_trusted = df_movies_IMDB.join(df_filmes_titulos_datas,\n",
				"                                   (df_movies_IMDB['tituloPincipal'].contains(df_filmes_titulos_datas['title'])) &\n",
				"                                   (df_movies_IMDB['anoLancamento'] == df_filmes_titulos_datas['releaseDate']),\n",
				"                                   'inner')\n",
				"\n",
				"# Remover as colunas 'title' e 'releaseDate' do DataFrame\n",
				"df_movies_IMDB_trusted = df_movies_IMDB_trusted.drop('title', 'releaseDate')\n",
				"\n",
				"# Renomear a coluna 'tituloPincipal' para 'tituloPrincipal' no DataFrame df_IMDB_filtrado_filmes\n",
				"df_movies_IMDB_trusted = df_movies_IMDB_trusted.withColumnRenamed(\"tituloPincipal\", \"tituloPrincipal\")\n",
				"\n",
				"df_movies_IMDB_trusted = df_movies_IMDB_trusted.distinct()\n",
				"\n",
				"# Trata os valores \"NA\" na coluna \"anoFalecimento\"\n",
				"df_movies_IMDB_trusted = df_movies_IMDB_trusted.withColumn(\"anoFalecimento\", when(col(\"anoFalecimento\") == \"\\\\N\", None).otherwise(col(\"anoFalecimento\")))\n",
				"\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 3. \n",
				"Filtro as Series do BD Local com lista de series do TMDB"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Converter a coluna 'name' e a substring de 'first_air_date' do DataFrame JSON para o DataFrame do TMDB\n",
				"df_series_nomes_datas = df_series_TMDB.select(col('name'), substring(col('first_air_date'), 1, 4).alias('dataLancamento'))\n",
				"\n",
				"# Realizar a filtragem dos títulos e anos de lançamento\n",
				"df_series_IMDB_layer1 = df_series_IMDB.join(df_series_nomes_datas,\n",
				"                                         (df_series_IMDB['tituloPincipal'].contains(df_series_nomes_datas['name'])) &\n",
				"                                         (df_series_IMDB['anoLancamento'] == df_series_nomes_datas['dataLancamento']),\n",
				"                                         'inner')\n",
				"\n",
				"# Remover as colunas 'name' e 'dataLancamento' do DataFrame\n",
				"df_series_IMDB_layer1 = df_series_IMDB_layer1.drop('name', 'dataLancamento')\n",
				"\n",
				"df_series_IMDB_layer1 = df_series_IMDB_layer1.distinct()\n",
				"\n",
				"# Renomear a coluna 'tituloPincipal' para 'tituloPrincipal' no DataFrame df_IMDB_filtrado_filmes\n",
				"df_series_IMDB_layer1 = df_series_IMDB_layer1.withColumnRenamed(\"tituloPincipal\", \"tituloPrincipal\")\n",
				"\n",
				"\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 4. \n",
				"Filtro as Series do BD Local que foram filtradas no passo 3\n",
				"\n",
				"com a dos filmes do BD local que foram filtrados no passo 2"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Filtrar apenas os títulos das séries correspondentes aos filmes\n",
				"df_filmes_correspondentes = df_movies_IMDB_trusted.select(col('tituloPrincipal').alias('titulo'))\n",
				"\n",
				"# Realizar a junção entre os dataframes de séries e títulos correspondentes usando contains\n",
				"df_series_IMDB_trusted = df_series_IMDB_layer1.join(df_filmes_correspondentes,\n",
				"                                            df_series_IMDB_layer1['tituloPrincipal'].contains(df_filmes_correspondentes['titulo']),\n",
				"                                            'inner')\n",
				"\n",
				"df_series_IMDB_trusted = df_series_IMDB_trusted.drop('titulo')\n",
				"\n",
				"# Remover linhas duplicadas no resultado\n",
				"df_series_IMDB_trusted = df_series_IMDB_trusted.distinct()\n",
				"\n",
				"# Trata os valores \"NA\" nas colunas\n",
				"df_series_IMDB_trusted = df_series_IMDB_trusted.withColumn(\"anoNascimento\", when(col(\"anoNascimento\") == \"\\\\N\", None).otherwise(col(\"anoNascimento\")))\n",
				"df_series_IMDB_trusted = df_series_IMDB_trusted.withColumn(\"anoFalecimento\", when(col(\"anoFalecimento\") == \"\\\\N\", None).otherwise(col(\"anoFalecimento\")))\n",
				"df_series_IMDB_trusted = df_series_IMDB_trusted.withColumn(\"anoTermino\", when(col(\"anoTermino\") == \"\\\\N\", None).otherwise(col(\"anoTermino\")))\n",
				"df_series_IMDB_trusted = df_series_IMDB_trusted.withColumn(\"tempoMinutos\", when(col(\"tempoMinutos\") == \"\\\\N\", None).otherwise(col(\"tempoMinutos\")))\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 5. \n",
				"Filtro as Series do TMDB com lista de Filmes do TMDB"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# Filtrar apenas os títulos das séries correspondentes aos filmes\n",
				"df_filmes_titulos = df_movies_TMDB.select(col('title').alias('titulo'))\n",
				"\n",
				"# Realizar a junção entre os dataframes de séries e títulos correspondentes usando contains\n",
				"df_series_TMDB_trusted = df_series_TMDB.join(df_filmes_titulos,\n",
				"                                            df_series_TMDB['name'].contains(df_filmes_titulos['titulo']),\n",
				"                                            'inner')\n",
				"\n",
				"df_series_TMDB_trusted = df_series_TMDB_trusted.drop('titulo','backdrop_path','poster_path')\n",
				"\n",
				"# Remover linhas duplicadas no resultado\n",
				"df_series_TMDB_trusted = df_series_TMDB_trusted.distinct()\n",
				"\n",
				"# Trata os valores \"NA\" nas colunas\n",
				"df_series_TMDB_trusted = df_series_TMDB_trusted.withColumn(\"first_air_date\", when(col(\"first_air_date\") == \"\", None).otherwise(col(\"first_air_date\")))\n",
				"df_series_TMDB_trusted = df_series_TMDB_trusted.withColumn(\"genre_ids\", when(size(col(\"genre_ids\")) == 0, None).otherwise(col(\"genre_ids\")))\n",
				"df_series_TMDB_trusted = df_series_TMDB_trusted.withColumn(\"overview\", when(col(\"overview\") == \"\", None).otherwise(col(\"overview\")))\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 6.\n",
				"Elimina algumas colunas não relevantes do df_movies_TMDB "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 12,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"# remove os colunas não relevantes\n",
				"df_movies_TMDB_trusted = df_movies_TMDB.drop('adult','backdrop_path','poster_path','video')"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"## 7.\n",
				"escreve os dados na camada Trusted no S3 no formato parquet\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"# Obtém a data atual para criar os diretórios correspondentes\n",
				"current_date = datetime.now()\n",
				"ano = current_date.strftime(\"%Y\")\n",
				"mes = current_date.strftime(\"%m\")\n",
				"dia = current_date.strftime(\"%d\")\n",
				"\n",
				"# Define os caminhos de destino no S3 para os DataFrames no formato Parquet\n",
				"path_trt_local_movies = \"s3://data-lake-do-fabricio/TRT/Local/Filmes/{ano}/{mes}/{dia}/\"\n",
				"path_trt_local_series = \"s3://data-lake-do-fabricio/TRT/Local/Series/{ano}/{mes}/{dia}/\"\n",
				"path_trt_tmdb_movies = \"s3://data-lake-do-fabricio/TRT/TMDB/Filmes/{ano}/{mes}/{dia}/\"\n",
				"path_trt_tmdb_series = \"s3://data-lake-do-fabricio/TRT/TMDB/Series/{ano}/{mes}/{dia}/\"\n",
				"\n",
				"# Salva os DataFrames no formato Parquet no S3\n",
				"df_movies_IMDB_trusted.write.parquet(path_trt_local_movies.format(ano=ano, mes=mes, dia=dia))\n",
				"df_series_IMDB_trusted.write.parquet(path_trt_local_series.format(ano=ano, mes=mes, dia=dia))\n",
				"df_movies_TMDB_trusted.write.parquet(path_trt_tmdb_movies.format(ano=ano, mes=mes, dia=dia))\n",
				"df_series_TMDB_trusted.write.parquet(path_trt_tmdb_series.format(ano=ano, mes=mes, dia=dia))"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
