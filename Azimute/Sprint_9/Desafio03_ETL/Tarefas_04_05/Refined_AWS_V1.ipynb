{
	"cells": [
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# AWS Glue Studio Notebook\n",
				"##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"####  Run this cell to set up and start your interactive session.\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"%idle_timeout 59\n",
				"%glue_version 3.0\n",
				"%worker_type G.1X\n",
				"%number_of_workers 2\n",
				"\n",
				"\n",
				"import sys\n",
				"from awsglue.transforms import *\n",
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.job import Job\n",
				"from pyspark.sql.functions import col, substring, regexp_replace, expr, size, levenshtein, avg, when, format_number, sum, lower\n",
				"from pyspark.sql import functions as F\n",
				"from datetime import datetime\n",
				"\n",
				"  \n",
				"sc = SparkContext.getOrCreate()\n",
				"glueContext = GlueContext(sc)\n",
				"spark = glueContext.spark_session\n",
				"job = Job(glueContext)\n",
				"\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"                                                                                \r"
					]
				}
			],
			"source": [
				"\n",
				"# Define os caminhos dos arquivos no S3\n",
				"path1 = \"s3://data-lake-do-fabricio/TRT/Local/CSV/Movies/2023/05/02/\"\n",
				"path2 = \"s3://data-lake-do-fabricio/TRT/Local/CSV/Series/2023/05/02/\"\n",
				"path3 = \"s3://data-lake-do-fabricio/TRT/TMDB/JSON/Movies/2023/05/24/\"\n",
				"path4 = \"s3://data-lake-do-fabricio/TRT/TMDB/JSON/Series/2023/05/24/\""
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Carrega os DataFrames\n",
				"df_movies_IMDB_trusted = spark.read.parquet(path1 + '')\n",
				"df_series_IMDB_trusted = spark.read.parquet(path2 + '')\n",
				"df_movies_TMDB_trusted = spark.read.parquet(path3 + '')\n",
				"df_series_TMDB_trusted = spark.read.parquet(path4 + '')"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 2. Normalização\n",
				"#### 2.1. Cria tabela movies IMDB"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [],
			"source": [
				"df_movies_IMDB = df_movies_IMDB_trusted.select(\"id\", \"tituloPrincipal\", \"tituloOriginal\", \"anoLancamento\", \"tempoMinutos\", \"genero\", \"notaMedia\", \"numeroVotos\")\n",
				"df_movies_IMDB = df_movies_IMDB.dropDuplicates(['id'])  # Remover duplicatas pelo ID\n",
				"df_movies_IMDB = df_movies_IMDB.withColumnRenamed(\"id\", \"movie_id\")  # Renomear a coluna \"id\" para \"movie_id\""
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### 2.2. Cria tabela series IMDB"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [],
			"source": [
				"df_series_IMDB = df_series_IMDB_trusted.select(\"id\", \"tituloPrincipal\", \"tituloOriginal\", \"anoLancamento\", \"anoTermino\", \"tempoMinutos\", \"genero\", \"notaMedia\", \"numeroVotos\")\n",
				"df_series_IMDB = df_series_IMDB.dropDuplicates(['id'])  # Remover duplicatas pelo ID\n",
				"df_series_IMDB = df_series_IMDB.withColumnRenamed(\"id\", \"seriesId\")  # Renomear a coluna \"id\" para \"movie_id\""
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 3.Junção \n",
				"\n",
				"### 3.1 Unir DF dos FILMES"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Aplicar regexp_replace no dataframe df_movies_TMDB\n",
				"df_movies_TMDB_titulos_datas = df_movies_TMDB_trusted.select(\n",
				"    regexp_replace(col('title'), r\"[^a-zA-Z0-9\\s]\", \"\").alias('title_replaced'),\n",
				"    substring(col('release_date'), 1, 4).alias('releaseDate'),\n",
				"    col('id'),\n",
				"    col('genre_ids'),\n",
				"    col('original_language'),\n",
				"    col('popularity'),\n",
				"    col('vote_average'),\n",
				"    col('vote_count'),\n",
				"    col('title'),\n",
				"    col('release_date')\n",
				")\n",
				"\n",
				"# Aplicar regexp_replace no dataframe df_movies_IMDB\n",
				"df_movies_IMDB_titulos_datas = df_movies_IMDB.select(\n",
				"    regexp_replace(col('tituloPrincipal'), r\"[^a-zA-Z0-9\\s]\", \"\").alias('tituloPrincipal_replaced'),\n",
				"    substring(col('anoLancamento'), 1, 4).alias('anoLancamento'),\n",
				"    col('movie_id'),\n",
				"    col('tituloOriginal'),\n",
				"    col('tempoMinutos'),\n",
				"    col('genero'),\n",
				"    col('notaMedia'),\n",
				"    col('numeroVotos')\n",
				")\n",
				"\n",
				"# Remover a sentença \"Final Chapter Part\" do dataframe df_movies_IMDB\n",
				"df_movies_IMDB_titulos_datas = df_movies_IMDB_titulos_datas.withColumn('tituloPrincipal_replaced', regexp_replace(col('tituloPrincipal_replaced'), 'Final Chapter Part', '')\n",
				")\n",
				"\n",
				"# Realizar a comparação de similaridade entre os títulos dos dataframes e filtrar pelo ano de lançamento\n",
				"df_movies_refined = df_movies_TMDB_titulos_datas.join(\n",
				"    df_movies_IMDB_titulos_datas,\n",
				"    expr(\n",
				"        \"(size(split(title_replaced, ' ')) = 1 AND \" +\n",
				"        \"size(filter(split(title_replaced, ' '), x -> length(x) > 3 AND instr(tituloPrincipal_replaced, x) > 0)) >= 1) OR \" +\n",
				"        \"(size(split(title_replaced, ' ')) = 2 AND \" +\n",
				"        \"size(filter(split(title_replaced, ' '), x -> length(x) >= 1 AND instr(tituloPrincipal_replaced, x) > 0)) >= 2) OR \" +\n",
				"        \"(size(split(title_replaced, ' ')) = 3 AND \" +\n",
				"        \"size(filter(split(title_replaced, ' '), x -> length(x) > 4 AND instr(tituloPrincipal_replaced, x) > 0)) >= 2) OR \" +\n",
				"        \"(size(split(title_replaced, ' ')) = 4 AND \" +\n",
				"        \"size(filter(split(title_replaced, ' '), x -> length(x) > 3 AND instr(tituloPrincipal_replaced, x) > 0)) >= 3) OR \" +\n",
				"        \"(size(split(title_replaced, ' ')) >= 5 AND \" +\n",
				"        \"size(filter(split(title_replaced, ' '), x -> length(x) >= 3 AND instr(tituloPrincipal_replaced, x) > 0)) >= 3 AND \" +\n",
				"        \"levenshtein(tituloPrincipal_replaced, title_replaced) <= 9)\"\n",
				"    ) &\n",
				"    (df_movies_TMDB_titulos_datas['releaseDate'] == df_movies_IMDB_titulos_datas['anoLancamento']) &\n",
				"    (col('tituloPrincipal_replaced').isNotNull()) &\n",
				"    (col('tituloPrincipal_replaced') != '') &\n",
				"    (col('title_replaced').isNotNull()) &\n",
				"    (col('title_replaced') != ''),\n",
				"    'left_outer'\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Calcular a soma de vote_count e numeroVotos (se não forem nulos)\n",
				"df_movies_refined = df_movies_refined.withColumn('votos', col('vote_count') + col('numeroVotos'))\n",
				"\n",
				"# Calcular a média de vote_average e notaMedia (se não forem nulos)\n",
				"df_movies_refined = df_movies_refined.withColumn('nota_media', when(\n",
				"    col('vote_count').isNotNull() & col('numeroVotos').isNotNull(),\n",
				"    (col('vote_average') * col('vote_count') + col('notaMedia') * col('numeroVotos')) / col('votos')\n",
				").otherwise(\n",
				"    when(col('vote_count').isNotNull(), col('vote_average')).otherwise(col('notaMedia'))\n",
				"))\n",
				"\n",
				"# Tratar valores nulos e arredondar a nota média ponderada para uma casa decimal\n",
				"df_movies_refined = df_movies_refined.withColumn('votos', when(col('votos').isNull(), col('vote_count')).otherwise(col('votos')))\n",
				"df_movies_refined = df_movies_refined.withColumn('nota_media', when(col('nota_media').isNull(), col('vote_average')).otherwise(col('nota_media')))\n",
				"df_movies_refined = df_movies_refined.withColumn('nota_media', format_number(col('nota_media'), 1))\n",
				"\n",
				"# Apagar as colunas indesejadas\n",
				"df_movies_refined = df_movies_refined.drop('releaseDate', 'tituloPrincipal_replaced', 'anoLancamento', 'title_replaced','vote_average','vote_count','notaMedia','numeroVotos','tituloOriginal','genero')\n",
				"\n",
				"# Selecione apenas as colunas desejadas\n",
				"df_movies_refined = df_movies_refined.select('id','movie_id','genre_ids', 'title', 'tempoMinutos', 'release_date', 'original_language', 'popularity', 'nota_media', 'votos')\n",
				"\n",
				"df_movies_refined = df_movies_refined.distinct()"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### 3.2. Filtrar Series TMDB por Filme do TMDB (antes de unir DF SERIES)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 8,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Aplicar regexp_replace no dataframe df_series_TMDB\n",
				"\n",
				"df_series_TMDB_titulos_datas = df_series_TMDB_trusted.select(\n",
				"    substring(col('first_air_date'), 1, 4).alias('releaseDate'),\n",
				"    col('name_replaced'),\n",
				"    col('id'),\n",
				"    col('genre_ids'),\n",
				"    col('original_language'),\n",
				"    col('popularity'),\n",
				"    col('vote_average'),\n",
				"    col('vote_count'),\n",
				"    col('name'),\n",
				"    col('first_air_date')\n",
				")\n",
				"\n",
				"# dataframe df_movies_TMDB\n",
				"df_movies_TMDB_titulos_datas = df_movies_TMDB_titulos_datas.select(col('title_replaced'))\n",
				"\n",
				"# Realizar a comparação de similaridade entre os títulos dos dataframes e filtrar pelo ano de lançamento\n",
				"df_series_TMDB_Layer1 = df_series_TMDB_titulos_datas.join(\n",
				"    df_movies_TMDB_titulos_datas,\n",
				"    expr(\n",
				"        \"(size(split(name_replaced, ' ')) = 1 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) > 3 AND instr(title_replaced, x) > 0)) >= 1) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) = 2 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) >= 1 AND instr(title_replaced, x) > 0)) >= 2) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) = 3 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) > 4 AND instr(title_replaced, x) > 0)) >= 2) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) = 4 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) > 3 AND instr(title_replaced, x) > 0)) >= 3) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) >= 5 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) >= 3 AND instr(title_replaced, x) > 0)) >= 3 AND \" +\n",
				"        \"levenshtein(title_replaced, name_replaced) <= 8)\"\n",
				"    ) &\n",
				"    (col('title_replaced').isNotNull()) &\n",
				"    (col('title_replaced') != '') &\n",
				"    (col('name_replaced').isNotNull()) &\n",
				"    (col('name_replaced') != ''),\n",
				"    'inner'\n",
				")\n",
				"\n",
				"# Apagar as colunas indesejadas\n",
				"df_series_TMDB_Layer1 = df_series_TMDB_Layer1.drop('title_replaced')"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### 3.1 Unir DF das SERIES"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Aplicar regexp_replace no dataframe df_movies_IMDB\n",
				"df_series_IMDB_titulos_datas = df_series_IMDB.select(\n",
				"    regexp_replace(col('tituloPrincipal'), r\"[^a-zA-Z0-9\\s]\", \"\").alias('tituloPrincipal_replaced'),\n",
				"    substring(col('anoLancamento'), 1, 4).alias('anoLancamento'),\n",
				"    col('seriesId'),\n",
				"    col('tituloPrincipal'),\n",
				"    col('tempoMinutos'),\n",
				"    col('anoTermino'),\n",
				"    col('notaMedia'),\n",
				"    col('numeroVotos')\n",
				")\n",
				"\n",
				"# Realizar a comparação de similaridade entre os títulos dos dataframes e filtrar pelo ano de lançamento\n",
				"df_series_refined = df_series_TMDB_Layer1.join(\n",
				"    df_series_IMDB_titulos_datas,\n",
				"    expr(\n",
				"        \"(size(split(name_replaced, ' ')) = 1 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) > 3 AND instr(tituloPrincipal_replaced, x) > 0)) >= 1) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) = 2 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) >= 1 AND instr(tituloPrincipal_replaced, x) > 0)) >= 2) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) = 3 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) > 4 AND instr(tituloPrincipal_replaced, x) > 0)) >= 2) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) = 4 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) > 3 AND instr(tituloPrincipal_replaced, x) > 0)) >= 3) OR \" +\n",
				"        \"(size(split(name_replaced, ' ')) >= 5 AND \" +\n",
				"        \"size(filter(split(name_replaced, ' '), x -> length(x) >= 3 AND instr(tituloPrincipal_replaced, x) > 0)) >= 3 AND \" +\n",
				"        \"levenshtein(tituloPrincipal_replaced, name_replaced) <= 9)\"\n",
				"    ) &\n",
				"    (df_series_TMDB_Layer1['releaseDate'] == df_series_IMDB_titulos_datas['anoLancamento']) &\n",
				"    (col('tituloPrincipal_replaced').isNotNull()) &\n",
				"    (col('tituloPrincipal_replaced') != '') &\n",
				"    (col('name_replaced').isNotNull()) &\n",
				"    (col('name_replaced') != ''),\n",
				"    'left_outer'\n",
				")\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Criar colunas com a soma dos votos e a média ponderada\n",
				"df_series_refined = df_series_refined.withColumn('votos', col('vote_count') + col('numeroVotos'))\n",
				"\n",
				"df_series_refined = df_series_refined.withColumn('nota_media', when(\n",
				"    col('vote_count').isNotNull() & col('numeroVotos').isNotNull(),\n",
				"    (col('vote_average') * col('vote_count') + col('notaMedia') * col('numeroVotos')) / col('votos')\n",
				").otherwise(\n",
				"    when(col('vote_count').isNotNull(), col('vote_average')).otherwise(col('notaMedia'))\n",
				"))\n",
				"\n",
				"# Tratar valores nulos e arredondar a nota média ponderada para uma casa decimal\n",
				"df_series_refined = df_series_refined.withColumn('votos', when(col('votos').isNull(), col('vote_count')).otherwise(col('votos')))\n",
				"df_series_refined = df_series_refined.withColumn('nota_media', when(col('nota_media').isNull(), col('vote_average')).otherwise(col('nota_media')))\n",
				"df_series_refined = df_series_refined.withColumn('nota_media', format_number(col('nota_media'), 1))\n",
				"\n",
				"# Apagar as colunas indesejadas\n",
				"df_series_refined = df_series_refined.drop('releaseDate', 'tituloPrincipal_replaced', 'releaseDate', 'name_replaced','vote_average','vote_count','notaMedia','numeroVotos','tituloPrincipal','anoLancamento')\n",
				"\n",
				"# Selecione apenas as colunas linhas desejadas\n",
				"df_series_refined = df_series_refined.select('id','seriesId','genre_ids', 'name', 'tempoMinutos', 'first_air_date', 'anoTermino', 'original_language', 'popularity', 'nota_media', 'votos')\n",
				"df_series_refined = df_series_refined.distinct()\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 4. Cria tabela actors  "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 28,
			"metadata": {},
			"outputs": [],
			"source": [
				"\n",
				"# Cria DF Actors\n",
				"df_movies_actors = df_movies_IMDB_trusted.select(\"id\", \"personagem\", \"nomeArtista\", \"generoArtista\", \"anoNascimento\", \"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\")\n",
				"df_series_actors = df_series_IMDB_trusted.select(\"id\", \"personagem\", \"nomeArtista\", \"generoArtista\", \"anoNascimento\", \"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\")\n",
				"\n",
				"\n",
				"# Obter a lista de film_ids presentes na tabela de filmes selecionados\n",
				"filme_ids = df_movies_refined.select(\"movie_id\")\n",
				"serie_ids = df_series_refined.select(\"seriesId\")\n",
				"\n",
				"\n",
				"# Realizar o join entre os DataFrames\n",
				"df_movies_actors = df_movies_actors.join(filme_ids, df_movies_actors[\"id\"] == filme_ids[\"movie_id\"], \"inner\")\n",
				"df_series_actors = df_series_actors.join(serie_ids, df_series_actors[\"id\"] == serie_ids[\"seriesId\"], \"inner\")\n",
				"\n",
				"# Apaga coluna desnecessaria\n",
				"df_movies_actors = df_movies_actors.drop(\"movie_id\")\n",
				"df_series_actors = df_series_actors.drop(\"seriesId\")\n",
				"\n",
				"# Apaga dados repetidos\n",
				"df_movies_actors = df_movies_actors.distinct()\n",
				"df_series_actors = df_series_actors.distinct()\n",
				"\n",
				"# Unir df Atores de filmes e series\n",
				"df_actors = df_movies_actors.unionAll(df_series_actors)\n",
				"df_actors = df_series_actors.withColumn(\"IdArtista\", F.monotonically_increasing_id())  # Adicionar uma coluna de ID único para os artistas\n"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 5. Cria Views  "
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"df_movies_refined.createOrReplaceTempView(\"movies\")\n",
				"df_series_refined.createOrReplaceTempView(\"series\")\n",
				"df_actors.createOrReplaceTempView(\"actors\")"
			]
		},
		{
			"attachments": {},
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"## 5. Escreve os dados na camada Refined no S3 no formato parquet\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"outputs": [],
			"source": [
				"\n",
				"# Obtém a data atual para criar os diretórios correspondentes\n",
				"current_date = datetime.now()\n",
				"ano = current_date.strftime(\"%Y\")\n",
				"mes = current_date.strftime(\"%m\")\n",
				"dia = current_date.strftime(\"%d\")\n",
				"\n",
				"# Define os caminhos de destino no S3 para os DataFrames no formato Parquet\n",
				"path_ref_movies = \"s3://data-lake-do-fabricio/Refined/Parquet/Movies/{ano}/{mes}/{dia}/\"\n",
				"path_ref_series = \"s3://data-lake-do-fabricio/Refined/Parquet/Series/{ano}/{mes}/{dia}/\"\n",
				"path_ref_actors = \"s3://data-lake-do-fabricio/Refined/Parquet/Actors/{ano}/{mes}/{dia}/\"\n",
				"\n",
				"# Salva os DataFrames no formato Parquet no S3\n",
				"df_movies_refined.write.parquet(path_ref_movies.format(ano=ano, mes=mes, dia=dia))\n",
				"df_series_refined.write.parquet(path_ref_series.format(ano=ano, mes=mes, dia=dia))\n",
				"df_actors.write.parquet(path_ref_actors.format(ano=ano, mes=mes, dia=dia))\n",
				"\n"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.11.3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
